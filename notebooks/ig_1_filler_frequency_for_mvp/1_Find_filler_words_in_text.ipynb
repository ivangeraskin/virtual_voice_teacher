{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "data_path = '../../data/processed/jiza'\n",
    "full_path = data_path+'/'+'10 глупых вопрос РЕСТАВРАТОРУ-qO-Qd-QUoUI.txt'\n",
    "text = pd.read_csv(full_path).columns[0]\n",
    "\n",
    "filler_words = 'да,точка,это самое,типо того,таки,собственно говоря,прямо,прикол,практически,походу,на самом деле,конкретно,как-то так,как сказать,как его,итак,знаешь,да ладно,все такое,в самом деле,в натуре,вот,эм,ну,вообще-то,так сказать,кстати,в общем,просто,ааа,мм,стало быть'\n",
    "filler_words = filler_words.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Функция анализа слов-паразитов для MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filler_word_analyse(text, filler_words):\n",
    "    \n",
    "    filler_cnt_dict = {}\n",
    "    \n",
    "    # Для каждого слова-паразита считаем кол-во вхождений\n",
    "    for filler in filler_words:\n",
    "        filler_cnt = text.count(' '+filler+' ')\n",
    "        if filler_cnt>0:\n",
    "            filler_cnt_dict[filler] = filler_cnt\n",
    "    \n",
    "    # Сортируем от максимального кол-ва вхождений к минимальному\n",
    "    filler_cnt_dict = {k: v for k, v in sorted(filler_cnt_dict.items(), key=lambda item: -item[1])}\n",
    "    \n",
    "    # Общее количество слов\n",
    "    all_words_cnt = text.count(' ')+1\n",
    "    \n",
    "    # Количество слов-паразитов\n",
    "    all_fillers_cnt = sum(filler_cnt_dict.values())\n",
    "    \n",
    "    # Доля филеров в процентах\n",
    "    fillers_pct = 100*all_fillers_cnt/all_words_cnt\n",
    "    \n",
    "    all_words = 'Всего слов - ' + str(all_words_cnt) + ' \\n \\n'\n",
    "    filler_words_pct = 'Доля слов паразитов - ' + str(np.round(fillers_pct,1)) +'% \\n \\n'\n",
    "    frequent_fillers = 'Встречаемость слов-паразитов: \\n'\n",
    "    \n",
    "    for filler in filler_cnt_dict:\n",
    "        filler_frequency = filler + ' - ' + str(filler_cnt_dict[filler]) + '\\n'\n",
    "        frequent_fillers = frequent_fillers + filler_frequency\n",
    "        \n",
    "    if all_words==0:\n",
    "        text_for_user = 'В записи не обнаружено ни одного слова, предлагаем сделать еще одну попытку. Говорите, не стесняйтесь)'\n",
    "    elif all_fillers_cnt==0:\n",
    "        text_for_user = 'В записи не обнаружено ни одного мусорного слова. Так держать. Расскажите еще что-нибудь) \\n \\n' + all_words\n",
    "    elif fillers_pct<=1: \n",
    "        conclusion = 'В вашей речи немного мусорных слов, но кое-что мы нашли. \\n \\n'\n",
    "        text_for_user = conclusion + all_words + filler_words_pct + frequent_fillers\n",
    "    elif 1<fillers_pct<=3: \n",
    "        conclusion = 'Слов-паразитов в вашей речи среднее количество, предлагаем еще потренироваться говорить без них. Продолжайте! \\n \\n'\n",
    "        text_for_user = conclusion + all_words + filler_words_pct + frequent_fillers\n",
    "    elif fillers_pct>3: \n",
    "        conclusion = 'Слов-паразитов в вашей речи достаточно много, предлагаем потренироваться говорить без них. Продолжайте! \\n \\n'\n",
    "        text_for_user = conclusion + all_words + filler_words_pct + frequent_fillers\n",
    "    \n",
    "    print(text_for_user)\n",
    "    \n",
    "    return text_for_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слов-паразитов в вашей речи среднее количество, предлагаем еще потренироваться говорить без них. Продолжайте! \n",
      " \n",
      "Всего слов - 2455 \n",
      " \n",
      "Доля слов паразитов - 1.4% \n",
      " \n",
      "Встречаемость слов-паразитов: \n",
      "вот - 13\n",
      "да - 6\n",
      "ну - 5\n",
      "просто - 5\n",
      "на самом деле - 4\n",
      "прямо - 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_for_user = filler_word_analyse(text,filler_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Статистика-аналитика слов паразитов в выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = listdir(data_path)\n",
    "all_text = ''\n",
    "for file in all_files:\n",
    "    add_text = pd.read_csv(data_path+'/'+file).columns[0]\n",
    "    all_text = all_text + add_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filler_cnt_dict = {}\n",
    "    \n",
    "# Для каждого слова-паразита считаем кол-во вхождений\n",
    "for filler in filler_words:\n",
    "    filler_cnt = all_text.count(' '+filler+' ')\n",
    "    if filler_cnt>0:\n",
    "        filler_cnt_dict[filler] = filler_cnt\n",
    "        \n",
    "# Сортируем от максимального кол-ва вхождений к минимальному\n",
    "filler_cnt_dict = {k: v for k, v in sorted(filler_cnt_dict.items(), key=lambda item: -item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Общее количество слов\n",
    "all_words_cnt = all_text.count(' ')+1\n",
    "\n",
    "# Количество слов-паразитов\n",
    "all_fillers_cnt = sum(filler_cnt_dict.values())\n",
    "\n",
    "# Доля филеров в процентах\n",
    "fillers_pct = str(np.round(100*all_fillers_cnt/all_words_cnt,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillers_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = 'Всего слов - ' + str(all_words_cnt) + ' \\n \\n'\n",
    "filler_pct = 'Доля слов паразитов - ' + fillers_pct +'% \\n \\n'\n",
    "frequent_fillers = 'Встречаемость слов-паразитов: \\n'\n",
    "\n",
    "for filler in filler_cnt_dict:\n",
    "    filler_word_pct = np.round(100*filler_cnt_dict[filler]/all_words_cnt,1)\n",
    "    filler_frequency = filler + ' - ' + str(filler_word_pct) + '%\\n'\n",
    "    frequent_fillers = frequent_fillers + filler_frequency\n",
    "\n",
    "analytics = all_words + filler_pct + frequent_fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов - 209717 \n",
      " \n",
      "Доля слов паразитов - 2.4% \n",
      " \n",
      "Встречаемость слов-паразитов: \n",
      "вот - 0.8%\n",
      "да - 0.5%\n",
      "просто - 0.4%\n",
      "ну - 0.3%\n",
      "на самом деле - 0.2%\n",
      "в общем - 0.0%\n",
      "кстати - 0.0%\n",
      "прямо - 0.0%\n",
      "практически - 0.0%\n",
      "таки - 0.0%\n",
      "знаешь - 0.0%\n",
      "так сказать - 0.0%\n",
      "вообще-то - 0.0%\n",
      "конкретно - 0.0%\n",
      "собственно говоря - 0.0%\n",
      "это самое - 0.0%\n",
      "точка - 0.0%\n",
      "как-то так - 0.0%\n",
      "да ладно - 0.0%\n",
      "как сказать - 0.0%\n",
      "как его - 0.0%\n",
      "итак - 0.0%\n",
      "все такое - 0.0%\n",
      "эм - 0.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(analytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
